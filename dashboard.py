import streamlit as st
import pandas as pd
import base64
import os
from src.pipeline import search_all_sources, process_offers # Noms des fonctions corrig√©s pour correspondre √† pipeline.py
from src.log_handler import setup_log_capture

# Configuration de la page Streamlit.
st.set_page_config(
    page_title="SkillScope | Analyseur de Comp√©tences",
    page_icon="assets/SkillScope.svg",
    layout="wide"
)

# Injection de CSS pour les marges.
st.markdown("""
<style>
    .main .block-container { padding-top: 2rem; padding-bottom: 2rem; }
</style>
""", unsafe_allow_html=True)

# Charge une image SVG pour l'affichage.
def load_svg(svg_file: str) -> str | None:
    if not os.path.exists(svg_file): return None
    with open(svg_file, "r", encoding="utf-8") as f: svg = f.read()
    svg_base64 = base64.b64encode(svg.encode('utf-8')).decode('utf-8')
    return f"data:image/svg+xml;base64,{svg_base64}"

# Affiche le logo et le titre.
logo_svg_base64 = load_svg("assets/SkillScope.svg")
if logo_svg_base64:
    st.markdown(f'<div style="text-align: center;"><img src="{logo_svg_base64}" width="300"></div>', unsafe_allow_html=True)
else:
    st.title("SkillScope")

st.markdown("""
<div style='text-align: center;'>
Un outil pour extraire et quantifier les comp√©tences les plus demand√©es sur le march√©.<br>
<em>Analyse bas√©e sur les offres de <strong>APEC</strong> et <strong>France Travail</strong>.</em>
</div>
""", unsafe_allow_html=True) # Texte mis √† jour : "Welcome to the Jungle" remplac√© par "APEC"
st.markdown("---")

# Centre le contenu de la page.
_left_margin, content_col, _right_margin = st.columns([0.2, 0.6, 0.2])

with content_col:
    # Barre de recherche et bouton de lancement.
    col1, col2 = st.columns([3, 1])
    with col1:
        job_to_scrape = st.text_input("Quel m√©tier analyser ?", placeholder="Ex: Data Engineer...", label_visibility="collapsed")
    with col2:
        launch_button = st.button("Lancer l'analyse", type="primary", use_container_width=True, disabled=(not job_to_scrape))
    
    # Conteneur dynamique pour afficher les r√©sultats ou les indicateurs de chargement.
    placeholder = st.empty()
    
    # Logique ex√©cut√©e au clic sur le bouton.
    if launch_button:
        # Nettoie la session pour une nouvelle analyse.
        for key in ['df_results', 'error_message', 'log_messages']: # Correction: Nettoyage sp√©cifique des cl√©s importantes
            if key in st.session_state: del st.session_state[key]
        st.session_state['job_title'] = job_to_scrape
        
        # Capture les logs et affiche les indicateurs de chargement dans le placeholder.
        with placeholder.container(), setup_log_capture() as log_capture_stream:
            # Spinner pour la phase de recherche.
            with st.spinner(f"Recherche des offres pour **{job_to_scrape}**..."):
                # Utilisation de search_all_sources (comme d√©fini dans pipeline.py)
                offers_metadata, _ = search_all_sources(job_to_scrape) # Suppression de 'cookies' car WTTJ est retir√©
            
            # Si la recherche a trouv√© des offres, on lance l'analyse.
            if offers_metadata:
                progress_text = "Analyse des comp√©tences en cours... Patientez."
                progress_bar = st.progress(0, text=progress_text)
                
                # Fonction pour mettre √† jour la barre de progression depuis le pipeline.
                def progress_callback(progress_percentage):
                    progress_bar.progress(progress_percentage, text=f"{progress_text} ({int(progress_percentage * 100)}%)")
                
                # Utilisation de process_offers (comme d√©fini dans pipeline.py), plus besoin de cookies
                df_results = process_offers(offers_metadata, None, progress_callback) 
                
                # Stocke les r√©sultats dans la session pour les afficher apr√®s le rerun.
                if df_results is not None and not df_results.empty:
                    st.session_state['df_results'] = df_results
                else:
                    st.session_state['error_message'] = "L'analyse a √©chou√© ou aucune comp√©tence n'a pu √™tre extraite."
            else:
                st.session_state['error_message'] = f"Aucune offre d'emploi n'a √©t√© trouv√©e pour '{job_to_scrape}'."
            
            # Sauvegarde les logs dans la session.
            st.session_state['log_messages'] = log_capture_stream.getvalue()
        
        # R√©-ex√©cute le script pour afficher les r√©sultats.
        st.rerun()
        
    # Affiche une erreur ou les r√©sultats stock√©s en session.
    with placeholder.container():
        if 'error_message' in st.session_state:
            st.error(st.session_state['error_message'], icon="üö®")
        elif 'df_results' in st.session_state:
            df = st.session_state['df_results']
            job_title = st.session_state.get('job_title', 'le m√©tier analys√©')
            
            st.subheader(f"üìä R√©sultats de l'analyse pour : {job_title}", anchor=False)
            
            # On compte la fr√©quence de chaque comp√©tence.
            tags_exploded = df['tags'].explode().dropna()
            
            if not tags_exploded.empty:
                skill_counts = tags_exploded.value_counts().reset_index()
                skill_counts.columns = ['Comp√©tence', 'Fr√©quence']
                skill_counts.insert(0, 'Classement', range(1, len(skill_counts) + 1))
                
                # Affiche les m√©triques principales.
                col1, col2, col3 = st.columns(3)
                col1.metric("Offres Analys√©es", f"{len(df)}")
                col2.metric("Comp√©tences Uniques", f"{len(skill_counts)}")
                col3.metric("Top Comp√©tence", skill_counts.iloc[0]['Comp√©tence'])
                
                # Affiche le tableau des comp√©tences.
                st.subheader("Classement des comp√©tences", anchor=False)
                search_skill = st.text_input("Rechercher une comp√©tence :", placeholder="Ex: Power BI...", label_visibility="collapsed")
                if search_skill:
                    skill_counts_display = skill_counts[skill_counts['Comp√©tence'].str.contains(search_skill, case=False, na=False)]
                else:
                    skill_counts_display = skill_counts
                
                st.dataframe(skill_counts_display, use_container_width=True, hide_index=True)
            else:
                st.warning("Aucune comp√©tence n'a pu √™tre extraite des offres analys√©es.")
        else:
            # Message par d√©faut au lancement.
            st.info("Lancez une analyse pour afficher les r√©sultats.", icon="üí°")

# Afficheur de logs en bas de page.
st.markdown("---")
with st.expander("Voir les logs d'ex√©cution", expanded=False):
    logs = st.session_state.get('log_messages', '')
    if logs: st.code(logs, language='log')
    else: st.text("Aucun log √† afficher pour le moment.")

# Footer.
st.markdown("---")
st.markdown("""
<div style="text-align: center; font-family: 'Source Sans Pro', sans-serif; margin-top: 40px;">
    <p style="font-size: 0.9em; margin-bottom: 10px;">D√©velopp√© par <strong style="color: #2474c5;">Hamza Kachmir</strong></p>
    <p style="font-size: 1.1em;">
        <a href="https://portfolio-hamza-kachmir.vercel.app/" target="_blank" style="text-decoration: none; margin-right: 15px;"><strong style="color: #F9B15C;">Portfolio</strong></a>
        <a href="https://www.linkedin.com/in/hamza-kachmir/" target="_blank" style="text-decoration: none;"><strong style="color: #F9B15C;">LinkedIn</strong></a>
    </p>
</div>
""", unsafe_allow_html=True)